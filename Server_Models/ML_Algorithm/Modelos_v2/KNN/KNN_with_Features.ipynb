{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries and load the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(\"C:\\\\Users\\\\london\\\\Documents\\\\Github\\\\Tese\\\\Disease_Dataset_Playground\\\\Server_Models\")\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from ML_Algorithm.Functions.compute_symptom_relatedness import compute_relatedness, compute_relatedness_matrix\n",
    "# from ML_Algorithm.Functions.compute_severity import get_severity_scores\n",
    "\n",
    "# Loading the severity scores\n",
    "with open(\"C:\\\\Users\\\\london\\\\Documents\\\\Github\\\\Tese\\\\Disease_Dataset_Playground\\\\Datasets\\\\step_4\\\\severity_scores.json\", \"r\") as f:\n",
    "    severity_mapping = json.load(f)\n",
    "\n",
    "# 1. Loading the Data\n",
    "file_path = \"C:\\\\Users\\\\london\\\\Documents\\\\Github\\\\Tese\\\\Documentation\\\\Dataset_Augmentation\\\\Augmented_database_29_09_2023.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"Augmented Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Transformation and Encoding\n",
    "\n",
    "# Replace NaN with 'None' placeholder\n",
    "symptom_cols = [f'Symptom_{i}' for i in range(1, 26)]\n",
    "df[symptom_cols] = df[symptom_cols].fillna('None')\n",
    "df['symptoms'] = df[symptom_cols].apply(lambda row: [symptom for symptom in row if symptom != 'None'], axis=1)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "X = mlb.fit_transform(df['symptoms'])\n",
    "\n",
    "# Insert the additional features calculation here\n",
    "def get_severity_scores(symptom_list):\n",
    "    return [severity_mapping.get(symptom, 0) for symptom in symptom_list]\n",
    "\n",
    "\n",
    "# Calculating additional features\n",
    "df['relatedness_values'] = df['symptoms'].apply(compute_relatedness_matrix)\n",
    "df['severity_values'] = df['symptoms'].apply(get_severity_scores)\n",
    "\n",
    "# Padding the relatedness matrix to a consistent shape\n",
    "max_dim = max([len(x) for x in df['relatedness_values']])\n",
    "\n",
    "def pad_matrix_to_shape(matrix, max_dim):\n",
    "    # Determine how much to pad\n",
    "    pad_dim = max_dim - matrix.shape[0]\n",
    "    \n",
    "    # Pad rows\n",
    "    matrix = np.pad(matrix, ((0, pad_dim), (0, pad_dim)), 'constant')\n",
    "    return matrix\n",
    "\n",
    "# After calculating max_dim in the training phase\n",
    "with open('max_dim.json', 'w') as f:\n",
    "    json.dump({\"max_dim\": max_dim}, f)\n",
    "\n",
    "\n",
    "# Apply padding to each matrix\n",
    "df['relatedness_values_padded'] = df['relatedness_values'].apply(lambda x: pad_matrix_to_shape(x, max_dim))\n",
    "\n",
    "# Padding the severity values to have the same length\n",
    "padded_severity = pad_sequences(df['severity_values'], padding='post', dtype='float32', maxlen=max_dim)\n",
    "\n",
    "# Now, reshaping the relatedness and severity features\n",
    "relatedness_features = np.array(df['relatedness_values_padded'].tolist()).reshape(len(df), -1)\n",
    "\n",
    "severity_features = padded_severity.reshape(len(df), -1)\n",
    "\n",
    "# Stacking them up with the binarized symptoms\n",
    "X = np.hstack((X, relatedness_features, severity_features))\n",
    "# X = np.hstack((X, relatedness_features))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['ICD 11'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train-test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Introducing SMOTE\n",
    "smote = SMOTE(k_neighbors=4, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Hyperparameter tunning\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# import numpy as np\n",
    "\n",
    "# # List of potential k values\n",
    "# k_values = list(range(1, 51))  # Checking values of k from 1 to 50.\n",
    "\n",
    "# cv_scores = []\n",
    "\n",
    "# # Perform cross-validation for each value of k\n",
    "# for k in k_values:\n",
    "#     knn = KNeighborsClassifier(n_neighbors=k)\n",
    "#     scores = cross_val_score(knn, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "#     cv_scores.append(np.mean(scores))\n",
    "\n",
    "# # Find the value of k that gave the highest accuracy\n",
    "# best_k = k_values[np.argmax(cv_scores)]\n",
    "# print(f\"Optimal value of k is: {best_k}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Training\n",
    "\n",
    "# Train the model with the best value of k and save it as `loaded_model`\n",
    "knn = KNeighborsClassifier(n_neighbors=4)  # You can optimize the number of neighbors based on cross-validation\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluation\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(13,11))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\",\n",
    "            cmap=plt.cm.Blues)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "\n",
    "# Ensure x and y ticks are displayed properly\n",
    "tick_interval = 20  # Adjust based on how many labels you want to show\n",
    "\n",
    "# Set ticks manually and force visibility\n",
    "plt.xticks(np.arange(0, conf_mat.shape[0], step=tick_interval), labels=np.arange(0, conf_mat.shape[0], step=tick_interval), fontsize=10)\n",
    "plt.yticks(np.arange(0, conf_mat.shape[1], step=tick_interval), labels=np.arange(0, conf_mat.shape[1], step=tick_interval), fontsize=10)\n",
    "\n",
    "# Force display of ticks by ensuring they are set correctly\n",
    "plt.tick_params(axis='x', which='major', labelsize=10, rotation=90)  # Rotate x labels for clarity\n",
    "plt.tick_params(axis='y', which='major', labelsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ROC Curve and AUC (only for binary classification or One-vs-All)\n",
    "if len(label_encoder.classes_) == 2:\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, knn.predict_proba(X_test)[:,1])\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC: {auc(fpr, tpr):.2f}')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Precision-Recall Curve (especially for imbalanced datasets)\n",
    "if len(label_encoder.classes_) == 2:  # Still keeping it for binary for simplicity\n",
    "    average_precision = average_precision_score(y_test, knn.predict_proba(X_test)[:,1])\n",
    "    precision, recall, _ = precision_recall_curve(y_test, knn.predict_proba(X_test)[:,1])\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.step(recall, precision, where='post')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(f'2-class Precision-Recall curve: AP={average_precision:0.2f}')\n",
    "    plt.show()\n",
    "\n",
    "# For Multiclass Precision-Recall Curve:\n",
    "else:\n",
    "    y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "    y_score = knn.predict_proba(X_test)\n",
    "    \n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "    average_precision = average_precision_score(y_test_bin, y_score, average=\"micro\")\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.step(recall, precision, where='post')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(f'Micro-averaged Precision-Recall curve: AP={average_precision:0.2f}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Model Deployment\n",
    "import joblib\n",
    "\n",
    "# Save the model, label encoder, and binarizer for later use\n",
    "model_filename = 'KNN_with_features.pkl'\n",
    "label_encoder_filename = 'disease_label_encoder.pkl'\n",
    "binarizer_filename = 'symptoms_binarizer.pkl'\n",
    "\n",
    "joblib.dump(knn, model_filename)\n",
    "joblib.dump(label_encoder, label_encoder_filename)\n",
    "joblib.dump(mlb, binarizer_filename)\n",
    "\n",
    "loaded_model = joblib.load(model_filename)\n",
    "loaded_label_encoder = joblib.load(label_encoder_filename)\n",
    "loaded_binarizer = joblib.load(binarizer_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Predict the top diseases based on confidence\n",
    "\n",
    "def predict_disease(symptoms_list, top_n=5):\n",
    "    \"\"\"\n",
    "    Given a list of symptoms (ICD-11 codes), predict the top potential diseases along with their confidence.\n",
    "    \"\"\"\n",
    "\n",
    "    # Transform the symptoms list into the appropriate binary vector format\n",
    "    symptoms_encoded = loaded_binarizer.transform([symptoms_list])  # `mlb` was previously used for multilabel binarization\n",
    "    \n",
    "    # Calculate the relatedness and severity features\n",
    "    relatedness_values = compute_relatedness_matrix(symptoms_list)\n",
    "    severity_values = get_severity_scores(symptoms_list)\n",
    "    \n",
    "    # Flatten the relatedness values matrix\n",
    "    flattened_relatedness = relatedness_values.reshape(-1)\n",
    "    \n",
    "    # Pad the flattened relatedness values to the length of max_dim^2\n",
    "    padded_relatedness = pad_sequences([flattened_relatedness], maxlen=max_dim*max_dim, padding='post', dtype='float32').reshape(1, -1)\n",
    "\n",
    "    padded_severity = pad_sequences([severity_values], maxlen=max_dim, padding='post', dtype='float32').reshape(1, -1)\n",
    "\n",
    "    # Combine all the features\n",
    "    # combined_features = np.hstack((symptoms_encoded, padded_relatedness, padded_severity))\n",
    "    combined_features = np.hstack((symptoms_encoded, padded_relatedness))\n",
    "\n",
    "    # Predict the probability distribution over classes using the trained model\n",
    "    disease_probabilities = knn.predict_proba(combined_features)\n",
    "\n",
    "    # Get indices of the top_n classes\n",
    "    top_indices = np.argsort(disease_probabilities[0])[-top_n:][::-1]\n",
    "\n",
    "    # Decode these indices to get the actual disease codes\n",
    "    top_diseases = loaded_label_encoder.inverse_transform(top_indices)\n",
    "    \n",
    "    # Extract their corresponding probabilities\n",
    "    top_probabilities = disease_probabilities[0][top_indices]\n",
    "\n",
    "    return list(zip(top_diseases, top_probabilities))\n",
    "\n",
    "# Test the prediction function\n",
    "sample_symptoms = ['MC15', '9D9Z', '9D90.6', '9C80.0', 'LD20.4', '8A68.Z', '9B73.3', '9B65.2', '1D01.Y', 'MA01.Z'] # 1F57.Z\tToxoplasmosis\n",
    "predicted_diseases_with_confidence = predict_disease(sample_symptoms)\n",
    "\n",
    "for disease, confidence in predicted_diseases_with_confidence:\n",
    "    print(f\"Disease: {disease} with confidence: {confidence*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
