{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries and load the dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Loading the Data\n",
    "file_path = \"/home/guilherme/Documents/GitHub/Tese/Documentation/Dataset_Augmentation/Augmented_database_29_09_2023.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"Augmented Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Transformation and Encoding\n",
    "\n",
    "# Replace NaN with 'None' placeholder\n",
    "symptom_cols = [f'Symptom_{i}' for i in range(1, 26)]\n",
    "df[symptom_cols] = df[symptom_cols].fillna('None')\n",
    "df['symptoms'] = df[symptom_cols].apply(lambda row: [symptom for symptom in row if symptom != 'None'], axis=1)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "X = mlb.fit_transform(df['symptoms'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['ICD 11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train/Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Introducing SMOTE\n",
    "smote = SMOTE(k_neighbors=4, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Hyperparameter tunning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define your RandomForestClassifier\n",
    "clf_template = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Set up parameter grid (adjust parameters and ranges accordingly)\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50], \n",
    "    'max_depth': [None, 10], \n",
    "    'min_samples_split': [2, 5, 10], \n",
    "    'max_features': [10, 25],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Run grid search\n",
    "grid_search = GridSearchCV(clf_template, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get best parameters and estimator\n",
    "best_params = grid_search.best_params_\n",
    "# best_clf = grid_search.best_estimator_\n",
    "\n",
    "# # Evaluate the best model\n",
    "# y_pred = best_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train the Random Forest Model\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    random_state=42,\n",
    "    max_features= best_params['max_features'],\n",
    "    class_weight=best_params['class_weight'],\n",
    "    bootstrap=best_params['bootstrap']\n",
    ")\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Model Evaluation\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the model: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred, labels=range(len(label_encoder.classes_)), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\",\n",
    "            cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Model Deployment\n",
    "import joblib\n",
    "\n",
    "# Save the model, label encoder, and binarizer for later use\n",
    "model_filename = 'RTF_no_features.pkl'\n",
    "label_encoder_filename = 'no_features_label_encoder.pkl'\n",
    "binarizer_filename = 'no_features_symptoms_binarizer.pkl'\n",
    "\n",
    "joblib.dump(clf, model_filename)\n",
    "joblib.dump(label_encoder, label_encoder_filename)\n",
    "joblib.dump(mlb, binarizer_filename)\n",
    "\n",
    "loaded_model = joblib.load(model_filename)\n",
    "loaded_label_encoder = joblib.load(label_encoder_filename)\n",
    "loaded_binarizer = joblib.load(binarizer_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Predict the disease\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def predict_disease(symptoms_list, top_n=5):\n",
    "    \"\"\"\n",
    "    Given a list of symptoms (ICD-11 codes), predict the top potential diseases along with their confidence.\n",
    "    \"\"\"\n",
    "    # Transform the symptoms list into the appropriate binary vector format\n",
    "    symptoms_encoded = loaded_binarizer.transform([symptoms_list])\n",
    "\n",
    "    # Predict the probability distribution over classes using the trained model\n",
    "    disease_probabilities = loaded_model.predict_proba(symptoms_encoded)\n",
    "\n",
    "    # Get indices of the top_n classes\n",
    "    top_indices = np.argsort(disease_probabilities[0])[-top_n:][::-1]\n",
    "\n",
    "    # Decode these indices to get the actual disease codes\n",
    "    top_diseases = loaded_label_encoder.inverse_transform(top_indices)\n",
    "    \n",
    "    # Extract their corresponding probabilities\n",
    "    top_probabilities = disease_probabilities[0][top_indices]\n",
    "\n",
    "    return list(zip(top_diseases, top_probabilities))\n",
    "\n",
    "# Test the prediction function\n",
    "sample_symptoms = ['MC15', '9D9Z', '9D90.6', '9C80.0', 'LD20.4', '8A68.Z', '9B73.3', '9B65.2', '1D01.Y', 'MA01.Z'] # 1F57.Z\tToxoplasmosis\n",
    "predicted_diseases_with_confidence = predict_disease(sample_symptoms)\n",
    "\n",
    "for disease, confidence in predicted_diseases_with_confidence:\n",
    "    print(f\"Disease: {disease} with confidence: {confidence*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
